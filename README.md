# ğŸ“Š MagangHub Scraper & Dashboard

Proyek ini melakukan **pengambilan data lowongan magang** dari [MagangHub Kemnaker RI](https://maganghub.kemnaker.go.id/) menggunakan **API internal**, kemudian menampilkan hasilnya dalam bentuk **dashboard interaktif** dengan **Streamlit**.

ğŸ‘‰ **Coba langsung di website:** [https://magangdash.streamlit.app/](https://magangdash.streamlit.app/)


---

## ğŸš€ Fitur

- ğŸ”„ **Scraping data otomatis** dari API MagangHub
- ğŸ’¾ Simpan hasil ke:
  - `data/maganghub_jobs.csv`
  - `data/maganghub_jobs.json`
- ğŸ“Š **Dashboard Streamlit**:
  - Grafik jumlah lowongan per kabupaten
  - Grafik jumlah lowongan per provinsi
  - Top 20 perusahaan dengan lowongan terbanyak
  - Tabel daftar lowongan dengan pagination
- ğŸ” Filter berdasarkan **perusahaan** & **lokasi**
- â¬‡ï¸ Download data hasil filter ke CSV langsung dari dashboard
- âš™ï¸ Dua mode penggunaan:
  - **CSV Lokal** â†’ membaca data dari file CSV hasil scraping
  - **API Online** â†’ langsung mengambil data terbaru dari API (mode ini lebih cocok untuk deploy di hosting)

---

## ğŸ“‚ Struktur Project

```
.
â”œâ”€â”€ api_client.py       # Modul untuk request ke API MagangHub
â”œâ”€â”€ utils.py            # Utility: simpan data ke CSV & JSON
â”œâ”€â”€ main.py             # Script scraping utama (generate CSV/JSON)
â”œâ”€â”€ app.py              # Dashboard Streamlit (dua mode: CSV & API)
â”œâ”€â”€ data/               # Folder hasil scraping (CSV & JSON)
â”œâ”€â”€ requirements.txt    # Daftar dependencies
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes
â””â”€â”€ README.md
```

---

## ğŸ“¦ Prasyarat

- Python **3.9+**
- Koneksi internet untuk mengakses API MagangHub
- Git (jika ingin clone repo)

---

## âš™ï¸ Instalasi

1. Clone repository ini:

```bash
git clone https://github.com/aisyahwulandr/maganghub-dashboard.git
cd maganghub-dashboard
```

2. Buat virtual environment (opsional tapi disarankan):

```bash
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ› ï¸ Cara Penggunaan

### 1. Mode CSV Lokal (default di laptop)
Jalankan scraper untuk mengambil data terbaru:

```bash
python main.py
```

Data akan otomatis tersimpan di:
- `data/maganghub_jobs.csv`
- `data/maganghub_jobs.json`

Lalu tampilkan dashboard:

```bash
streamlit run app.py
```

Dashboard akan bisa diakses di:  
ğŸ‘‰ http://localhost:8501/

### 2. Mode API Online (disarankan untuk deploy)
Anda bisa memilih mode **API Online** di sidebar dashboard.  
Pada mode ini, app akan langsung mengambil data dari API tanpa membutuhkan file CSV.  

---

## ğŸŒ Deploy ke Streamlit Cloud

1. Pastikan file `requirements.txt` sudah ada dengan isi minimal:
   ```
   streamlit
   pandas
   plotly
   requests
   ```
2. Push kode ke repository GitHub Anda.
3. Deploy ke [Streamlit Cloud](https://streamlit.io/cloud).
4. **Gunakan mode API Online** saat di cloud.  
   âš ï¸ Catatan: jika menggunakan mode CSV Lokal, file CSV akan hilang setelah restart karena storage di cloud bersifat sementara (ephemeral).

ğŸ‘‰ Hasil deploy project ini dapat langsung dicoba di:  
ğŸ”— [https://magangdash.streamlit.app/](https://magangdash.streamlit.app/)

---

## ğŸ”® Roadmap

- [ ] Auto-refresh data setiap X jam di background
- [ ] Deploy dashboard ke **Streamlit Cloud / Render / Heroku**
- [ ] Tambah filter berdasarkan **program studi** & **jenjang**
- [ ] Visualisasi timeline (jadwal magang)
- [ ] Simpan data ke database (contoh: SQLite / PostgreSQL) untuk lebih stabil

---

## ğŸ“œ Lisensi

Proyek ini dibuat untuk tujuan **belajar & personal use**.  
Tidak untuk penggunaan komersial tanpa izin.
